{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f99128>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    \n",
    "    return (x - min_val) /(max_val - min_val)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "matches = {}\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    global matches\n",
    "    initial_count = len(matches)\n",
    "    for i in x:\n",
    "        if i in matches.keys():\n",
    "            continue\n",
    "        else:\n",
    "            matches[i] = initial_count\n",
    "            initial_count += 1\n",
    "\n",
    "    class_num = len(matches)\n",
    "    sample_num = len(x)\n",
    "    t = np.zeros(shape=(sample_num, class_num))\n",
    "    for i, j in enumerate(x, 0):\n",
    "        t[i][matches[j]] = 1\n",
    "    return t\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(shape=(None, image_shape[0], image_shape[1], image_shape[2]), dtype=tf.float32, name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(shape=(None, n_classes), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(dtype=tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(2, 2)\n",
      "(4, 4)\n",
      "(?, 8, 8, 10)\n",
      "(2, 2)\n",
      "(2, 2)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(conv_num_outputs)\n",
    "    print(conv_ksize)\n",
    "    print(conv_strides)\n",
    "    filter_width = conv_ksize[0]\n",
    "    filter_height = conv_ksize[1]\n",
    "    input_channel = x_tensor.get_shape().as_list()[3]\n",
    "    output_channel = conv_num_outputs\n",
    "    strides = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    filterW = tf.Variable(tf.truncated_normal((filter_width, filter_height, input_channel, output_channel), stddev=0.1), tf.float32)\n",
    "    filterB = tf.Variable(tf.zeros(output_channel))\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(x_tensor, filterW, strides, padding=\"VALID\")\n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(conv2, filterB))\n",
    "    print(conv2.shape)\n",
    "    print(pool_ksize)\n",
    "    print(pool_strides)\n",
    "    pool_k = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    pool_s = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    max_pool = tf.nn.max_pool(conv2, ksize=pool_k, strides=pool_s, padding=\"SAME\")\n",
    "\n",
    "    return max_pool \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    image_size = 1\n",
    "    for i in x_tensor.get_shape().as_list()[1:]:\n",
    "        image_size *= i\n",
    "    print(image_size)\n",
    "    return tf.reshape(x_tensor, shape=[-1, image_size])\n",
    "    \"\"\"\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全连接的层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 30, 30, 6)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "12\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 13, 13, 12)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "18\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 5, 5, 18)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "162\n",
      "6\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 30, 30, 6)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "12\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 13, 13, 12)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "18\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 5, 5, 18)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "162\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 6, [3, 3], [1, 1], [2, 2], [2, 2])\n",
    "    conv1 = tf.nn.dropout(x=conv1, keep_prob=keep_prob)\n",
    "    conv2 = conv2d_maxpool(conv1, 12, [3, 3], [1, 1], [2, 2], [2, 2])\n",
    "    conv2 = tf.nn.dropout(x=conv2, keep_prob=keep_prob)\n",
    "    conv3 = conv2d_maxpool(conv2, 18, [3, 3], [1, 1], [2, 2], [2, 2])\n",
    "    conv3 = tf.nn.dropout(x=conv3, keep_prob=keep_prob)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "       #flatten(x_tensor)\n",
    "    conv3 = flatten(conv3)\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    conv3 = fully_conn(conv3, 15)\n",
    "    #conv3 = tf.nn.dropout(x=conv3, keep_prob=keep_prob)\n",
    "    \n",
    "    conv4 = fully_conn(conv3, 15)\n",
    "    #conv4 = tf.nn.dropout(x=conv4, keep_prob=keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    conv4 = output(conv3, 10)\n",
    "    # TODO: return output\n",
    "    return conv4\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    feed = {x: feature_batch, y: label_batch, keep_prob: keep_probability}\n",
    "    session.run([optimizer], feed_dict = feed)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    feed = {x: feature_batch, y: label_batch, keep_prob: 1.0}\n",
    "    loss, prediction, = session.run([cost, accuracy], feed_dict=feed)\n",
    "    print(\"loss is {:.1f} \".format(loss), \n",
    "          \"accuracy is {:.1f} \".format(prediction))\n",
    "    feed = {x: valid_features, y: valid_labels, keep_prob: 1.0}\n",
    "    val_loss, val_prediction, = session.run([cost, accuracy], feed_dict=feed)\n",
    "    print(\"val loss is {:.1f}\".format(val_loss),\n",
    "          \"val accuracy is {:.1f}\".format(val_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss is 2.3  accuracy is 0.1 \n",
      "val loss is 2.3 val accuracy is 0.1\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss is 2.3  accuracy is 0.1 \n",
      "val loss is 2.3 val accuracy is 0.2\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss is 2.2  accuracy is 0.2 \n",
      "val loss is 2.1 val accuracy is 0.3\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss is 2.1  accuracy is 0.3 \n",
      "val loss is 1.9 val accuracy is 0.3\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss is 2.0  accuracy is 0.4 \n",
      "val loss is 1.8 val accuracy is 0.3\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss is 2.0  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.3\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss is 2.0  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.4 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 43, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 64, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 85, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 87, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss is 2.3  accuracy is 0.1 \n",
      "val loss is 2.3 val accuracy is 0.1\n",
      "Epoch  1, CIFAR-10 Batch 2:  loss is 2.2  accuracy is 0.2 \n",
      "val loss is 2.2 val accuracy is 0.2\n",
      "Epoch  1, CIFAR-10 Batch 3:  loss is 2.1  accuracy is 0.2 \n",
      "val loss is 2.1 val accuracy is 0.2\n",
      "Epoch  1, CIFAR-10 Batch 4:  loss is 2.1  accuracy is 0.2 \n",
      "val loss is 2.0 val accuracy is 0.3\n",
      "Epoch  1, CIFAR-10 Batch 5:  loss is 2.0  accuracy is 0.3 \n",
      "val loss is 1.9 val accuracy is 0.3\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss is 2.0  accuracy is 0.2 \n",
      "val loss is 1.9 val accuracy is 0.3\n",
      "Epoch  2, CIFAR-10 Batch 2:  loss is 1.9  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.3\n",
      "Epoch  2, CIFAR-10 Batch 3:  loss is 1.7  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.3\n",
      "Epoch  2, CIFAR-10 Batch 4:  loss is 1.8  accuracy is 0.2 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  2, CIFAR-10 Batch 5:  loss is 1.8  accuracy is 0.4 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 2:  loss is 1.8  accuracy is 0.4 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 3:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 4:  loss is 1.7  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 5:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.4 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  4, CIFAR-10 Batch 2:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  4, CIFAR-10 Batch 3:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  4, CIFAR-10 Batch 4:  loss is 1.7  accuracy is 0.3 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  4, CIFAR-10 Batch 5:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  5, CIFAR-10 Batch 2:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  5, CIFAR-10 Batch 3:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  5, CIFAR-10 Batch 4:  loss is 1.7  accuracy is 0.2 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  5, CIFAR-10 Batch 5:  loss is 1.6  accuracy is 0.3 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch  6, CIFAR-10 Batch 2:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch  6, CIFAR-10 Batch 3:  loss is 1.3  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch  6, CIFAR-10 Batch 4:  loss is 1.7  accuracy is 0.3 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  6, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.4\n",
      "Epoch  7, CIFAR-10 Batch 2:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  7, CIFAR-10 Batch 3:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  7, CIFAR-10 Batch 4:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  7, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  8, CIFAR-10 Batch 2:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  8, CIFAR-10 Batch 3:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  8, CIFAR-10 Batch 4:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  8, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  9, CIFAR-10 Batch 2:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  9, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  9, CIFAR-10 Batch 4:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  9, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 10, CIFAR-10 Batch 2:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 10, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 10, CIFAR-10 Batch 4:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 10, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 11, CIFAR-10 Batch 2:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 11, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 11, CIFAR-10 Batch 4:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 11, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.3 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 12, CIFAR-10 Batch 2:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 12, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 12, CIFAR-10 Batch 4:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 12, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.3 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 13, CIFAR-10 Batch 2:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 13, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 13, CIFAR-10 Batch 4:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 13, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 14, CIFAR-10 Batch 2:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 14, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 14, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 14, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 15, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 15, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 15, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 15, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 16, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 16, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 16, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 16, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 17, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 17, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 17, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 17, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 18, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 18, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 18, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 19, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 19, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 19, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 19, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.4 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 20, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 20, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 20, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 20, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.4 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 21, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 21, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 21, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 21, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.4 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 22, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 22, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 22, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 22, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 23, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 23, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 23, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 23, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 24, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 24, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 24, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 24, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 25, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 25, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 25, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 25, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 26, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 26, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 26, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 26, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 27, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 27, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 27, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 27, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 28, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 28, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 28, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 28, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 29, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 29, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 29, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 29, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 30, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 30, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 30, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 30, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 31, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 31, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 31, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 31, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 32, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 32, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 32, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 32, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 33, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 33, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 33, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 33, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 34, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 34, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 34, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 34, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 35, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 35, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 35, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 36, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 36, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 36, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 36, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.5\n",
      "Epoch 37, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 37, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 37, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 37, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.5\n",
      "Epoch 38, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 38, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 38, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 38, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 39, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 39, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 39, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 39, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 40, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 40, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 40, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 40, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 41, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 41, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 41, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 41, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 42, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 42, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 42, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 42, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 43, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 43, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 43, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 43, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 43, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 44, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 44, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 44, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 44, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 45, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 45, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 45, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 45, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 46, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 46, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 46, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 46, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.4 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 47, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 47, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 47, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 47, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.4 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 48, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 48, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 48, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 48, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.4 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 49, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 49, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 49, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 49, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 50, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 50, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 50, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 50, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 51, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 51, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 51, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 51, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.4 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 52, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 52, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 52, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 53, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 53, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 53, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 53, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 54, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 54, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 54, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 54, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.4 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 55, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 55, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 55, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 55, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 56, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 56, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 56, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 56, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 57, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 57, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 57, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 57, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 58, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 58, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 58, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 58, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 59, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 59, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 59, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 59, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 60, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 60, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 60, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 60, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 61, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 61, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 61, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 61, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 62, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 62, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 62, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 62, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 63, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 63, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 63, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 63, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.4 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 64, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 64, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 64, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 64, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 64, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 65, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 65, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 65, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 65, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 66, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 66, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 66, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 66, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 67, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 67, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 67, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 67, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 68, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 68, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 68, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 68, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 69, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 69, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 69, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 70, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 70, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 70, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 70, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 71, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 71, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 71, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 71, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 72, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 72, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 72, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 72, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 73, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 73, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 73, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 73, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 74, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 74, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 74, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 74, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 75, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 75, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 75, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 75, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 76, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 76, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 76, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 76, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 77, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 77, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 77, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 77, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 78, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 78, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 78, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 78, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 79, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 79, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 79, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 79, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 80, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 80, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 80, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 80, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 81, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 81, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 81, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 81, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 82, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 82, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 82, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 82, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 83, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 83, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 83, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 83, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 84, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 84, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 84, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 84, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 85, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 85, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 85, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 85, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 85, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 86, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 86, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 86, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 86, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 87, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 87, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 87, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 87, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 88, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 88, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 88, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 88, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 89, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 89, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 89, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 89, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 90, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 90, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 90, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 90, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 91, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 91, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 91, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 91, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 92, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 92, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 92, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 92, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 93, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 93, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 93, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 93, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 94, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 94, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 94, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 94, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 95, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 95, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 95, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 95, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 96, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 96, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 96, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 96, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 97, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 97, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 97, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 97, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 98, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 98, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 98, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 98, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 99, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 99, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 99, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 99, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 100, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 100, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 100, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 100, CIFAR-10 Batch 5:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.58505859375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1034b0f0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
