{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f99128>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    \n",
    "    return (x - min_val) /(max_val - min_val)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "matches = {}\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    global matches\n",
    "    initial_count = len(matches)\n",
    "    for i in x:\n",
    "        if i in matches.keys():\n",
    "            continue\n",
    "        else:\n",
    "            matches[i] = initial_count\n",
    "            initial_count += 1\n",
    "\n",
    "    class_num = len(matches)\n",
    "    sample_num = len(x)\n",
    "    t = np.zeros(shape=(sample_num, class_num))\n",
    "    for i, j in enumerate(x, 0):\n",
    "        t[i][matches[j]] = 1\n",
    "    return t\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(shape=(None, image_shape[0], image_shape[1], image_shape[2]), dtype=tf.float32, name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(shape=(None, n_classes), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(dtype=tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(2, 2)\n",
      "(4, 4)\n",
      "(?, 8, 8, 10)\n",
      "(2, 2)\n",
      "(2, 2)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(conv_num_outputs)\n",
    "    print(conv_ksize)\n",
    "    print(conv_strides)\n",
    "    filter_width = conv_ksize[0]\n",
    "    filter_height = conv_ksize[1]\n",
    "    input_channel = x_tensor.get_shape().as_list()[3]\n",
    "    output_channel = conv_num_outputs\n",
    "    strides = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    filterW = tf.Variable(tf.truncated_normal((filter_width, filter_height, input_channel, output_channel), stddev=0.1), tf.float32)\n",
    "    filterB = tf.Variable(tf.zeros(output_channel))\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(x_tensor, filterW, strides, padding=\"VALID\")\n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(conv2, filterB))\n",
    "    print(conv2.shape)\n",
    "    print(pool_ksize)\n",
    "    print(pool_strides)\n",
    "    pool_k = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    pool_s = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    max_pool = tf.nn.max_pool(conv2, ksize=pool_k, strides=pool_s, padding=\"SAME\")\n",
    "\n",
    "    return max_pool \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    image_size = 1\n",
    "    for i in x_tensor.get_shape().as_list()[1:]:\n",
    "        image_size *= i\n",
    "    print(image_size)\n",
    "    return tf.reshape(x_tensor, shape=[-1, image_size])\n",
    "    \"\"\"\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全连接的层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 30, 30, 32)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "48\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 13, 13, 48)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "64\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 5, 5, 64)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "576\n",
      "32\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 30, 30, 32)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "48\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 13, 13, 48)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "64\n",
      "[3, 3]\n",
      "[1, 1]\n",
      "(?, 5, 5, 64)\n",
      "[2, 2]\n",
      "[2, 2]\n",
      "576\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 32, [3, 3], [1, 1], [2, 2], [2, 2])\n",
    "    conv1 = tf.nn.dropout(x=conv1, keep_prob=keep_prob)\n",
    "    conv2 = conv2d_maxpool(conv1, 48, [3, 3], [1, 1], [2, 2], [2, 2])\n",
    "    conv2 = tf.nn.dropout(x=conv2, keep_prob=keep_prob)\n",
    "    conv3 = conv2d_maxpool(conv2, 64, [3, 3], [1, 1], [2, 2], [2, 2])\n",
    "    conv3 = tf.nn.dropout(x=conv3, keep_prob=keep_prob)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "       #flatten(x_tensor)\n",
    "    conv3 = flatten(conv3)\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    conv3 = fully_conn(conv3, 128)\n",
    "    #conv3 = tf.nn.dropout(x=conv3, keep_prob=keep_prob)\n",
    "    \n",
    "    conv4 = fully_conn(conv3, 256)\n",
    "    #conv4 = tf.nn.dropout(x=conv4, keep_prob=keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    conv4 = output(conv3, 10)\n",
    "    # TODO: return output\n",
    "    return conv4\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    feed = {x: feature_batch, y: label_batch, keep_prob: keep_probability}\n",
    "    session.run([optimizer], feed_dict = feed)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    feed = {x: feature_batch, y: label_batch, keep_prob: 1.0}\n",
    "    loss, prediction, = session.run([cost, accuracy], feed_dict=feed)\n",
    "    print(\"loss is {:.1f} \".format(loss), \n",
    "          \"accuracy is {:.1f} \".format(prediction))\n",
    "    feed = {x: valid_features, y: valid_labels, keep_prob: 1.0}\n",
    "    val_loss, val_prediction, = session.run([cost, accuracy], feed_dict=feed)\n",
    "    print(\"val loss is {:.1f}\".format(val_loss),\n",
    "          \"val accuracy is {:.1f}\".format(val_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss is 2.3  accuracy is 0.2 \n",
      "val loss is 2.3 val accuracy is 0.1\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss is 2.3  accuracy is 0.1 \n",
      "val loss is 2.2 val accuracy is 0.2\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss is 2.2  accuracy is 0.3 \n",
      "val loss is 2.1 val accuracy is 0.2\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss is 2.1  accuracy is 0.3 \n",
      "val loss is 2.0 val accuracy is 0.3\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss is 1.9  accuracy is 0.4 \n",
      "val loss is 1.9 val accuracy is 0.3\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss is 1.7  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.5 \n",
      "val loss is 1.6 val accuracy is 0.5\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 43, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 64, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 85, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 87, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 1.0 val accuracy is 0.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  loss is 2.3  accuracy is 0.1 \n",
      "val loss is 2.3 val accuracy is 0.1\n",
      "Epoch  1, CIFAR-10 Batch 2:  loss is 2.3  accuracy is 0.2 \n",
      "val loss is 2.3 val accuracy is 0.2\n",
      "Epoch  1, CIFAR-10 Batch 3:  loss is 2.1  accuracy is 0.2 \n",
      "val loss is 2.2 val accuracy is 0.2\n",
      "Epoch  1, CIFAR-10 Batch 4:  loss is 2.1  accuracy is 0.2 \n",
      "val loss is 2.1 val accuracy is 0.3\n",
      "Epoch  1, CIFAR-10 Batch 5:  loss is 2.0  accuracy is 0.3 \n",
      "val loss is 2.0 val accuracy is 0.3\n",
      "Epoch  2, CIFAR-10 Batch 1:  loss is 2.0  accuracy is 0.4 \n",
      "val loss is 1.9 val accuracy is 0.3\n",
      "Epoch  2, CIFAR-10 Batch 2:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  2, CIFAR-10 Batch 3:  loss is 1.8  accuracy is 0.2 \n",
      "val loss is 1.9 val accuracy is 0.3\n",
      "Epoch  2, CIFAR-10 Batch 4:  loss is 1.7  accuracy is 0.3 \n",
      "val loss is 1.8 val accuracy is 0.4\n",
      "Epoch  2, CIFAR-10 Batch 5:  loss is 1.8  accuracy is 0.3 \n",
      "val loss is 1.7 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 1:  loss is 1.8  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 2:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 3:  loss is 1.5  accuracy is 0.3 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 4:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  3, CIFAR-10 Batch 5:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  4, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  4, CIFAR-10 Batch 2:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  4, CIFAR-10 Batch 3:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.6 val accuracy is 0.4\n",
      "Epoch  4, CIFAR-10 Batch 4:  loss is 1.5  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  4, CIFAR-10 Batch 5:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  5, CIFAR-10 Batch 1:  loss is 1.6  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  5, CIFAR-10 Batch 2:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.5 val accuracy is 0.5\n",
      "Epoch  5, CIFAR-10 Batch 3:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  5, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  5, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  6, CIFAR-10 Batch 1:  loss is 1.5  accuracy is 0.4 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  6, CIFAR-10 Batch 2:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  6, CIFAR-10 Batch 3:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  6, CIFAR-10 Batch 4:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  6, CIFAR-10 Batch 5:  loss is 1.4  accuracy is 0.6 \n",
      "val loss is 1.4 val accuracy is 0.5\n",
      "Epoch  7, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch  7, CIFAR-10 Batch 2:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch  7, CIFAR-10 Batch 3:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch  7, CIFAR-10 Batch 4:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.5\n",
      "Epoch  7, CIFAR-10 Batch 5:  loss is 1.3  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch  8, CIFAR-10 Batch 1:  loss is 1.4  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch  8, CIFAR-10 Batch 2:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch  8, CIFAR-10 Batch 3:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch  8, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch  8, CIFAR-10 Batch 5:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch  9, CIFAR-10 Batch 1:  loss is 1.3  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch  9, CIFAR-10 Batch 2:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.3 val accuracy is 0.6\n",
      "Epoch  9, CIFAR-10 Batch 3:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch  9, CIFAR-10 Batch 4:  loss is 1.2  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch  9, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 10, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 10, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 10, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 10, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 10, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 11, CIFAR-10 Batch 1:  loss is 1.2  accuracy is 0.5 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 11, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 11, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 11, CIFAR-10 Batch 4:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 11, CIFAR-10 Batch 5:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 12, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 12, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.2 val accuracy is 0.6\n",
      "Epoch 12, CIFAR-10 Batch 3:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 12, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 12, CIFAR-10 Batch 5:  loss is 1.1  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 13, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 13, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 13, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 13, CIFAR-10 Batch 4:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 13, CIFAR-10 Batch 5:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 14, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 14, CIFAR-10 Batch 2:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 14, CIFAR-10 Batch 3:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 14, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 14, CIFAR-10 Batch 5:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 15, CIFAR-10 Batch 1:  loss is 1.1  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 15, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 15, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 15, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 15, CIFAR-10 Batch 5:  loss is 1.0  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 16, CIFAR-10 Batch 1:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 16, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 16, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 16, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 16, CIFAR-10 Batch 5:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 17, CIFAR-10 Batch 1:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 17, CIFAR-10 Batch 2:  loss is 1.0  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 17, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 17, CIFAR-10 Batch 4:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 17, CIFAR-10 Batch 5:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 18, CIFAR-10 Batch 1:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.6 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 18, CIFAR-10 Batch 3:  loss is 0.7  accuracy is 0.9 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 18, CIFAR-10 Batch 4:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 18, CIFAR-10 Batch 5:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 19, CIFAR-10 Batch 1:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 19, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 19, CIFAR-10 Batch 3:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 19, CIFAR-10 Batch 4:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 19, CIFAR-10 Batch 5:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 20, CIFAR-10 Batch 1:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 20, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 20, CIFAR-10 Batch 3:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 20, CIFAR-10 Batch 4:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 20, CIFAR-10 Batch 5:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.1 val accuracy is 0.6\n",
      "Epoch 21, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 21, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 21, CIFAR-10 Batch 3:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 21, CIFAR-10 Batch 4:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 21, CIFAR-10 Batch 5:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 22, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 22, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 22, CIFAR-10 Batch 3:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 22, CIFAR-10 Batch 4:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 22, CIFAR-10 Batch 5:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 23, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 23, CIFAR-10 Batch 2:  loss is 0.9  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 23, CIFAR-10 Batch 3:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 23, CIFAR-10 Batch 4:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 23, CIFAR-10 Batch 5:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 24, CIFAR-10 Batch 1:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 24, CIFAR-10 Batch 2:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 24, CIFAR-10 Batch 3:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 24, CIFAR-10 Batch 4:  loss is 0.7  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 24, CIFAR-10 Batch 5:  loss is 0.8  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 25, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 25, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 25, CIFAR-10 Batch 3:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.6\n",
      "Epoch 25, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 25, CIFAR-10 Batch 5:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 26, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 26, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 26, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 26, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 26, CIFAR-10 Batch 5:  loss is 0.8  accuracy is 0.7 \n",
      "val loss is 1.0 val accuracy is 0.7\n",
      "Epoch 27, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.7 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 27, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 27, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 27, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 27, CIFAR-10 Batch 5:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 28, CIFAR-10 Batch 1:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 28, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 28, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 28, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 28, CIFAR-10 Batch 5:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 29, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.7 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 29, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 29, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 29, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 29, CIFAR-10 Batch 5:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 30, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 30, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 30, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 30, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 30, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 31, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 31, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 31, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 31, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 31, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 32, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 32, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 32, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 32, CIFAR-10 Batch 4:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 32, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 33, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 33, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 33, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 33, CIFAR-10 Batch 4:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 33, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 34, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 34, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 34, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 34, CIFAR-10 Batch 4:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 34, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 35, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 35, CIFAR-10 Batch 2:  loss is 0.7  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 35, CIFAR-10 Batch 4:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 35, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 36, CIFAR-10 Batch 1:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 36, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 36, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 36, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 36, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 37, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 37, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 37, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 37, CIFAR-10 Batch 4:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 37, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 38, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 38, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 38, CIFAR-10 Batch 3:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 38, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 38, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 39, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 39, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 39, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 39, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 39, CIFAR-10 Batch 5:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 40, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 40, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 40, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 40, CIFAR-10 Batch 4:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 40, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 41, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 41, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 41, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 41, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 41, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 42, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 42, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 42, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 42, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 42, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 43, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 43, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 43, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 43, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 43, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 44, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 44, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 44, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 44, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 44, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 45, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 45, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 45, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 45, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 45, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 46, CIFAR-10 Batch 1:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 46, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 46, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 46, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 46, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 47, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 47, CIFAR-10 Batch 2:  loss is 0.6  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 47, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 47, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 47, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 48, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.8 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 48, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 48, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 48, CIFAR-10 Batch 4:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 48, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 49, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 49, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 49, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 49, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 49, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.8 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 50, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 50, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 50, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 50, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 50, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 51, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.8 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 51, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 51, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 51, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 51, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 52, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 52, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 52, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 52, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 53, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 53, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 53, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 53, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 53, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 54, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 54, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 54, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 54, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 54, CIFAR-10 Batch 5:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 55, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 55, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 55, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 55, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 55, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 56, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 56, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 56, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 56, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 56, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 57, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 57, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 57, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 57, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 57, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.8 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 58, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 58, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 58, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 58, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 58, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 59, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 59, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 59, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 59, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 59, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 60, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 60, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 60, CIFAR-10 Batch 3:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 60, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 60, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 61, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 61, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 61, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 61, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 61, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 62, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 62, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 62, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 62, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 62, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 63, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 63, CIFAR-10 Batch 2:  loss is 0.5  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 63, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 63, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 63, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 64, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 64, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.9 val accuracy is 0.7\n",
      "Epoch 64, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 64, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 64, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 65, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 65, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 65, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 65, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 65, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 66, CIFAR-10 Batch 1:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 66, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 66, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 66, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 66, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 67, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 67, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 67, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 67, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 67, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 68, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 68, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 68, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 68, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 68, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 69, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 69, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 69, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 69, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 70, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 70, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 70, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 70, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 70, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 71, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 71, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 71, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 71, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 71, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 72, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 72, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 72, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 72, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 72, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 73, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 73, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 73, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 73, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 73, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 74, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 74, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 74, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 74, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 74, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 75, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 75, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 75, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 75, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 75, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 76, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 76, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 76, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 76, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 76, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 77, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 77, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 77, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 77, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 77, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 78, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 78, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 78, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 78, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 78, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 79, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 79, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 79, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 79, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 79, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 80, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 80, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 80, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 80, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 80, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 81, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 81, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 81, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 81, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 81, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 82, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 82, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 82, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 82, CIFAR-10 Batch 4:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 82, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 83, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 83, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 83, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 83, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 83, CIFAR-10 Batch 5:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 84, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 84, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 84, CIFAR-10 Batch 3:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 84, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 84, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 85, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 85, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 85, CIFAR-10 Batch 3:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 85, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 85, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 86, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 86, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 86, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 86, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 86, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 87, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 87, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 87, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 87, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 88, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 88, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 88, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 88, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 88, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 89, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 89, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 89, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 89, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 89, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 90, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 90, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 90, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 90, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 90, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 91, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 91, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 91, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 91, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 91, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 92, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 92, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 92, CIFAR-10 Batch 3:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 92, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 92, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 93, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 93, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 93, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 93, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 93, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 94, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 94, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 94, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 94, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 94, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 95, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 95, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 95, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 95, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 95, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 96, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 96, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 96, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 96, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 96, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 97, CIFAR-10 Batch 1:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 97, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 97, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 97, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 97, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 98, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 98, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 98, CIFAR-10 Batch 3:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 98, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 98, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 99, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.8\n",
      "Epoch 99, CIFAR-10 Batch 2:  loss is 0.4  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 99, CIFAR-10 Batch 3:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 99, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 99, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 100, CIFAR-10 Batch 1:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 100, CIFAR-10 Batch 2:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 100, CIFAR-10 Batch 3:  loss is 0.2  accuracy is 1.0 \n",
      "val loss is 0.8 val accuracy is 0.7\n",
      "Epoch 100, CIFAR-10 Batch 4:  loss is 0.2  accuracy is 0.9 \n",
      "val loss is 0.7 val accuracy is 0.7\n",
      "Epoch 100, CIFAR-10 Batch 5:  loss is 0.3  accuracy is 0.9 \n",
      "val loss is 0.8 val accuracy is 0.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.71005859375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREJPr/Muv5l1PakKkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5e3a20>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
